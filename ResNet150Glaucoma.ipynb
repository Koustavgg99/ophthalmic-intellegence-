{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hkYPEcu5odTS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, Add, GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pCV1k8ARoymI"
   },
   "outputs": [],
   "source": [
    "# Define the ResNet150 model\n",
    "def residual_block(x, filters, kernel_size=3, stride=1, conv_shortcut=True, name=None):\n",
    "    bn_axis = 3 if tf.keras.backend.image_data_format() == 'channels_last' else 1\n",
    "\n",
    "    if conv_shortcut:\n",
    "        shortcut = Conv2D(4 * filters, 1, strides=stride, name=name + '_0_conv')(x)\n",
    "        shortcut = BatchNormalization(axis=bn_axis, name=name + '_0_bn')(shortcut)\n",
    "    else:\n",
    "        shortcut = x\n",
    "\n",
    "    x = Conv2D(filters, 1, strides=stride, name=name + '_1_conv')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=name + '_1_bn')(x)\n",
    "    x = Activation('relu', name=name + '_1_relu')(x)\n",
    "\n",
    "    x = Conv2D(filters, kernel_size, padding='same', name=name + '_2_conv')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=name + '_2_bn')(x)\n",
    "    x = Activation('relu', name=name + '_2_relu')(x)\n",
    "\n",
    "    x = Conv2D(4 * filters, 1, name=name + '_3_conv')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=name + '_3_bn')(x)\n",
    "\n",
    "    x = Add(name=name + '_add')([shortcut, x])\n",
    "    x = Activation('relu', name=name + '_out')(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uDxEE7WXo6Gh"
   },
   "outputs": [],
   "source": [
    "def stack_blocks(x, filters, blocks, stride1=2, name=None):\n",
    "    x = residual_block(x, filters, stride=stride1, name=name + '_block1')\n",
    "    for i in range(2, blocks + 1):\n",
    "        x = residual_block(x, filters, conv_shortcut=False, name=name + '_block' + str(i))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BqYZw0oao90g"
   },
   "outputs": [],
   "source": [
    "def ResNet150(input_shape=(224, 224, 3)):\n",
    "    img_input = Input(shape=input_shape)\n",
    "\n",
    "    bn_axis = 3 if tf.keras.backend.image_data_format() == 'channels_last' else 1\n",
    "\n",
    "    x = Conv2D(64, 7, strides=2, padding='same', name='conv1_conv')(img_input)\n",
    "    x = BatchNormalization(axis=bn_axis, name='conv1_bn')(x)\n",
    "    x = Activation('relu', name='conv1_relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(3, strides=2, padding='same', name='pool1_pool')(x)\n",
    "\n",
    "    x = stack_blocks(x, 64, 3, stride1=1, name='conv2')\n",
    "    x = stack_blocks(x, 128, 8, name='conv3')\n",
    "    x = stack_blocks(x, 256, 36, name='conv4')\n",
    "    x = stack_blocks(x, 512, 3, name='conv5')\n",
    "\n",
    "    model = Model(img_input, x, name='resnet150')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zNeXMcdJpEyS"
   },
   "outputs": [],
   "source": [
    "# Define paths to your dataset\n",
    "train_data_dir = '/content/drive/MyDrive/Glaucoma annoted/training'\n",
    "test_data_dir = '/content/drive/MyDrive/Glaucoma annoted/validation'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DnULDDwxpInu",
    "outputId": "9ff7964f-c86c-41a0-b58a-d281f7d40bed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 16\n"
     ]
    }
   ],
   "source": [
    "# Define batch size and number of epochs\n",
    "batch_size = 16\n",
    "epochs = 100\n",
    "input_shape = (224, 224)  # Assuming images are resized to 224x224\n",
    "\n",
    "print(f\"Batch size: {batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9xbA5BW-pPSM"
   },
   "outputs": [],
   "source": [
    "# Data Augmentation and Image Preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "14UAvvp0pTIe",
    "outputId": "c96fc18f-8f7d-473e-f7ca-28df904bcd1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 735 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow training images in batches using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=input_shape,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'  # Since we use binary_crossentropy loss\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uzW1MrZGpYDw",
    "outputId": "5e216ad0-aba2-41e5-da76-8fa3a72a77a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 116 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Flow validation images in batches using test_datagen generator\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=input_shape,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6I3qR-0ipbpy"
   },
   "outputs": [],
   "source": [
    "# Load the ResNet150 model\n",
    "base_model = ResNet150(input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5VprCfcYphGs",
    "outputId": "0ea9117c-924a-4e98-ee9a-82b01d633a3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in training data: 735\n",
      "Batch size: 16\n"
     ]
    }
   ],
   "source": [
    "# Freeze all layers in the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "print(f\"Number of samples in training data: {train_generator.samples}\")\n",
    "print(f\"Batch size: {batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "88TMlfmhpnWn",
    "outputId": "819cc975-89fe-4525-c1a1-d63fd8c7377b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples: 735\n",
      "Total validation samples: 116\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total data count for training and validation datasets\n",
    "total_train_samples = train_generator.samples\n",
    "total_validation_samples = validation_generator.samples\n",
    "\n",
    "print(f\"Total training samples: {total_train_samples}\")\n",
    "print(f\"Total validation samples: {total_validation_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_F6IkCNqptHo"
   },
   "outputs": [],
   "source": [
    "# Add custom layers on top of ResNet150\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0AEPgTjKpxAO",
    "outputId": "5b32e200-dd5a-4c39-eb6a-4b47ee7aefb1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "45/45 [==============================] - 426s 9s/step - loss: 0.7173 - accuracy: 0.4882 - val_loss: 0.6850 - val_accuracy: 0.4375\n",
      "Epoch 2/150\n",
      "45/45 [==============================] - 453s 10s/step - loss: 0.6696 - accuracy: 0.5494 - val_loss: 0.6656 - val_accuracy: 0.4375\n",
      "Epoch 3/150\n",
      "45/45 [==============================] - 442s 10s/step - loss: 0.6402 - accuracy: 0.5869 - val_loss: 0.6864 - val_accuracy: 0.5714\n",
      "Epoch 4/150\n",
      "45/45 [==============================] - 407s 9s/step - loss: 0.6332 - accuracy: 0.6245 - val_loss: 0.6465 - val_accuracy: 0.4375\n",
      "Epoch 5/150\n",
      "45/45 [==============================] - 379s 8s/step - loss: 0.5875 - accuracy: 0.7636 - val_loss: 0.5594 - val_accuracy: 0.8393\n",
      "Epoch 6/150\n",
      "45/45 [==============================] - 419s 9s/step - loss: 0.5403 - accuracy: 0.7719 - val_loss: 0.5114 - val_accuracy: 0.9911\n",
      "Epoch 7/150\n",
      "45/45 [==============================] - 391s 9s/step - loss: 0.5081 - accuracy: 0.7955 - val_loss: 0.4633 - val_accuracy: 0.9643\n",
      "Epoch 8/150\n",
      "45/45 [==============================] - 404s 9s/step - loss: 0.4335 - accuracy: 0.8985 - val_loss: 0.4298 - val_accuracy: 0.8482\n",
      "Epoch 9/150\n",
      "45/45 [==============================] - 436s 10s/step - loss: 0.3909 - accuracy: 0.8943 - val_loss: 0.3604 - val_accuracy: 0.9554\n",
      "Epoch 10/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.3859 - accuracy: 0.8470"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=150,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "62YJwbjop4eK"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(validation_generator)\n",
    "print(f'Validation loss: {loss:.4f}, Validation accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
